{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "w_4ULs2AnPkt"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNIwyjfzu38QTG9BJRarmu3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuvarbiv/DQN/blob/main/recreating_Baroch's_article.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ALL FUNCTIONS"
      ],
      "metadata": {
        "id": "jfRQpCqr8wF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random, math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import types\n",
        "from matplotlib import animation\n",
        "from IPython.display import HTML\n",
        "from types import SimpleNamespace\n",
        "\n",
        "# --------------------------------------------\n",
        "def print_state(datasets, frame) :\n",
        "  print(f\"---------frame: {frame}-----------\")\n",
        "  print(f\"grid:\\n{datasets.grid}\")\n",
        "  print(f\"agents_loc:\\n{datasets.agents_loc}\")\n",
        "  print(f\"----------------------------------\")\n"
      ],
      "metadata": {
        "id": "ITKrI1_Q8xKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------\n",
        "def inner_cell_loop(const_HP, var_HP, datasets, i, j, frame):\n",
        "  datasets.cell_by_agent = []\n",
        "  for a in datasets.agents_loc:\n",
        "      d = np.hypot(a[0]-i, a[1]-j)\n",
        "      s = cell_send_pulse(const_HP, var_HP, datasets, i, j) # Use current_alpha\n",
        "      r = agent_recieved_signal(const_HP, var_HP, datasets, d) if s else 0 # Use current_lamda\n",
        "      datasets.cell_by_agent.append(cell_update_probabillity(const_HP, var_HP, datasets, frame, datasets.grid[i][j], d, r))\n",
        "  update_cell(const_HP, var_HP, datasets, i, j, frame)\n",
        "  update_target_set(const_HP, var_HP, datasets, i, j, frame, datasets.grid[i][j]) # Use current_threshold\n",
        "\n",
        "# --------------------------------------------\n",
        "def cell_send_pulse(const_HP, var_HP, datasets, i, j):\n",
        "  # return: 1==pulse, 0==no_pulse\n",
        "  # later I'd like this function to return continuous value [0,1]\n",
        "  if (i,j) in datasets.targets_loc:        return random.random() < const_HP.P_ta\n",
        "  if (i,j) in datasets.false_targets_loc:  return random.random() < var_HP.alpha*const_HP.P_ta\n",
        "  return False\n",
        "\n",
        "# --------------------------------------------\n",
        "def agent_recieved_signal(const_HP, var_HP, datasets, d):\n",
        "  # return: 1==pulse, 0==no_pulse\n",
        "  # TODO: later I'd like this function to return continuous value [0,1]\n",
        "  x = math.e**(-d/var_HP.lamda)\n",
        "  return random.random() < x\n",
        "\n",
        "# --------------------------------------------\n",
        "def cell_update_probabillity(const_HP, var_HP, datasets, frame, prev_grid_val, d, recieved):\n",
        "  min_value = 0.01\n",
        "  P_recieved__t0 = prev_grid_val\n",
        "  NP_recieved__t0 = 1-P_recieved__t0\n",
        "  # recieved\n",
        "  numerator =             P_recieved__t0 * const_HP.P_ta\n",
        "  denumerator = numerator + NP_recieved__t0 * const_HP.P_ta * var_HP.alpha\n",
        "  P_signal_recieved__t1 = numerator / denumerator if denumerator != 0 else min_value # Avoid division by zero\n",
        "  # UNrecieved\n",
        "  signal_strength = 1-math.e**(-d/var_HP.lamda)\n",
        "  numerator =           P_recieved__t0 * (const_HP.NP_ta + const_HP.P_ta*signal_strength)\n",
        "  denumerator = numerator + NP_recieved__t0 * ((1-var_HP.alpha*const_HP.P_ta)+var_HP.alpha*const_HP.P_ta*signal_strength)\n",
        "  P_signal_UNrecieved__t1 = numerator / denumerator if denumerator != 0 else min_value # Avoid division by zero\n",
        "\n",
        "  if recieved:\n",
        "    return max(P_signal_recieved__t1,min_value) # Using the calculated received probability\n",
        "  else:\n",
        "    return max(P_signal_UNrecieved__t1,min_value) # Using the calculated unreceived probability\n",
        "\n",
        "# --------------------------------------------\n",
        "def update_cell(const_HP, var_HP, datasets, i, j, frame):\n",
        "  new_val = np.mean(datasets.cell_by_agent)\n",
        "  datasets.grid[i][j] = new_val\n",
        "\n",
        "# --------------------------------------------\n",
        "def update_target_set(const_HP, var_HP, datasets, i, j, frame, new_grid_val):\n",
        "  if new_grid_val >= var_HP.threshold and (i,j) not in [(t[0], t[1]) for t in datasets.target_set]:\n",
        "    datasets.target_set.add((i,j,frame))\n",
        "    datasets.detect_img[i, j] = frame  # reflect into detection image\n",
        "    pairs,frame = print_targets_found(datasets)\n",
        "\n",
        "# --------------------------------------------\n",
        "def print_targets_found(datasets):\n",
        "  pairs = [f\"({i}),({j})\" for i,j, _ in datasets.target_set]\n",
        "  steps = [steps for _, _, steps in datasets.target_set]\n",
        "  return pairs,steps\n"
      ],
      "metadata": {
        "id": "J1AbjYWinTEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------\n",
        "def move_all_agents(const_HP, var_HP, datasets):\n",
        "  agents_COM = calc_agents_COM(const_HP, var_HP, datasets)\n",
        "  entropy_COM = calc_entropy_COM(datasets.grid)\n",
        "\n",
        "  if const_HP.print:\n",
        "    print(datasets.grid)\n",
        "    print(f\"entropy_COM: {entropy_COM}\")\n",
        "  for a in range(const_HP.nof_agents):\n",
        "    move_agent(const_HP, var_HP, datasets, a, agents_COM, entropy_COM)\n",
        "\n",
        "# --------------------------------------------\n",
        "def calc_agents_COM(const_HP, var_HP, datasets):\n",
        "  # agents center of mass\n",
        "  # agents_array = np.array(datasets.agents_loc)\n",
        "  # return np.full(const_HP.nof_agents, agents_array.mean(axis=0))   # average over rows\n",
        "\n",
        "  # nearest agent TODO treat the case of 1 agent\n",
        "  nearest = []\n",
        "  for a in range(const_HP.nof_agents):\n",
        "    nearest_dist = const_HP.GSize**2\n",
        "    nearest_agent_loc = None  # Initialize to None or some indicator\n",
        "    my_loc = datasets.agents_loc[a]\n",
        "    for n in range(const_HP.nof_agents):\n",
        "      dist = ((datasets.agents_loc[a][0] - datasets.agents_loc[n][0])**2 + (datasets.agents_loc[a][1] - datasets.agents_loc[n][1])**2)**0.5\n",
        "      if dist < nearest_dist and n != a:\n",
        "        nearest_dist = dist\n",
        "        nearest_agent_loc = datasets.agents_loc[n] # Store the location directly\n",
        "    nearest.append(nearest_agent_loc) # Append the nearest agent's location\n",
        "\n",
        "  return nearest\n",
        "\n",
        "# --------------------------------------------\n",
        "def calc_entropy_COM(grid, baseline_p=0.01, eps=1e-9):\n",
        "    H = bernoulli_entropy(grid)\n",
        "    H_base = bernoulli_entropy(baseline_p)        # scalar\n",
        "    w = H - H_base                                # excess entropy\n",
        "    w[w < eps] = 0.0                              # kill numerical noise\n",
        "    if w.sum() == 0:\n",
        "        return (-1,-1)\n",
        "    rows, cols = np.indices(w.shape)\n",
        "    y_cm = (rows * w).sum() / w.sum()\n",
        "    x_cm = (cols * w).sum() / w.sum()\n",
        "    return (y_cm, x_cm)\n",
        "\n",
        "# --------------------------------------------\n",
        "def bernoulli_entropy(p):\n",
        "    p = np.clip(p, 1e-12, 1-1e-12)\n",
        "    return -(p*np.log2(p) + (1-p)*np.log2(1-p))\n",
        "\n",
        "# --------------------------------------------\n",
        "def move_agent(const_HP, var_HP, datasets, agent_num, agents_COM, entropy_COM):\n",
        "  # Pass the location of the current agent's nearest neighbor\n",
        "  datasets.agents_loc[agent_num] = next_location(datasets, agent_num, agents_COM[agent_num], entropy_COM, datasets.grid.shape, 1)\n",
        "\n",
        "# --------------------------------------------\n",
        "def next_location(datasets, agent_num, nearest_agent_loc, entropy_COM, grid_shape, k=0.5):\n",
        "    \"\"\"\n",
        "    o: (i,j) current location\n",
        "    x: (i,j) location to avoid (nearest agent)\n",
        "    y: (i,j) location to approach (entropy COM)\n",
        "    grid_shape: (rows, cols)\n",
        "    k: weighting factor (importance of avoiding x vs. approaching y)\n",
        "       k > 1 -> stronger avoidance of x\n",
        "       k < 1 -> stronger pull toward y\n",
        "    \"\"\"\n",
        "    o = datasets.agents_loc[agent_num]\n",
        "    oi, oj = o\n",
        "    rows, cols = grid_shape\n",
        "\n",
        "    neighbors = [\n",
        "        (oi+di, oj+dj)\n",
        "        for di in [-1, 0, 1]\n",
        "        for dj in [-1, 0, 1]\n",
        "    ]\n",
        "\n",
        "    # keep inside boundaries\n",
        "    neighbors = [(i, j) for i, j in neighbors if 0 <= i < rows and 0 <= j < cols]\n",
        "\n",
        "    def score(loc):\n",
        "        i, j = loc\n",
        "        # print(i,j,nearest_agent_loc,entropy_COM)\n",
        "        d_y = np.hypot(i - entropy_COM[0], j - entropy_COM[1])   # distance to y\n",
        "        # Check if nearest_agent_loc is not None before accessing its elements\n",
        "        if nearest_agent_loc is not None:\n",
        "            d_x = np.hypot(i - nearest_agent_loc[0], j - nearest_agent_loc[1])   # distance to x\n",
        "        else:\n",
        "            d_x = 0 # Or handle this case as appropriate for your logic\n",
        "\n",
        "        return -d_y + k * d_x\n",
        "\n",
        "    # Handle the case where neighbors is empty (e.g., 1x1 grid)\n",
        "    if not neighbors:\n",
        "        return o  # Stay at the current location if no neighbors are available\n",
        "\n",
        "    best = max(neighbors, key=score)\n",
        "    return best"
      ],
      "metadata": {
        "id": "6oDg8ROtnS-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------\n",
        "def set_images(const_HP, var_HP, datasets, Gim, Tim):\n",
        "  # global texts  # Declare texts as global\n",
        "\n",
        "  # Clear previous texts\n",
        "  texts = []\n",
        "  # for text in texts:\n",
        "      # text.remove()\n",
        "\n",
        "  # update agent scatters on both axes\n",
        "  ax = [c[1] for c in datasets.agents_loc]  # x = col (j)\n",
        "  ay = [c[0] for c in datasets.agents_loc]  # y = row (i)\n",
        "  xy = np.column_stack([ax, ay])            # shape (N, 2)\n",
        "  agents_scatter_T.set_offsets(xy)\n",
        "\n",
        "  # update both images\n",
        "  Gim.set_data(datasets.grid)\n",
        "  Tim.set_data(datasets.detect_img)\n",
        "\n",
        "  # Add text annotations for detected targets\n",
        "  for i in range(const_HP.GSize):\n",
        "    for j in range(const_HP.GSize):\n",
        "      if datasets.detect_img[i, j] > 0:\n",
        "        text = Tax.text(j, i, int(datasets.detect_img[i, j]), ha=\"center\", va=\"center\", color=\"black\")\n",
        "        texts.append(text)\n",
        "\n",
        "  # return a FLAT list of artists\n",
        "  return [Gim, Tim] + texts\n"
      ],
      "metadata": {
        "id": "LaoEBHOtnSup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1 RUN + SIMULATION"
      ],
      "metadata": {
        "id": "xNKs17Sm8zVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- model hyper-parameters -----\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "const_HP = SimpleNamespace()\n",
        "const_HP.P_ta = 1\n",
        "const_HP.NP_ta = 1 - const_HP.P_ta\n",
        "const_HP.nof_iterations = 50\n",
        "const_HP.nof_agents = 3\n",
        "const_HP.nof_targets = 3\n",
        "const_HP.nof_false_targets = 3\n",
        "const_HP.GSize = 20\n",
        "const_HP.print = False\n",
        "var_HP = SimpleNamespace()\n",
        "var_HP.threshold = 0.9\n",
        "var_HP.alpha = 0.5\n",
        "var_HP.lamda = 10\n",
        "\n",
        "# ----- initialize datasets -----\n",
        "datasets = SimpleNamespace()\n",
        "datasets.grid = np.full((const_HP.GSize, const_HP.GSize), const_HP.nof_targets/(const_HP.GSize**2), dtype=float)\n",
        "datasets.agents_loc = random.sample([(i,j) for i in range(const_HP.GSize) for j in range(const_HP.GSize)], const_HP.nof_agents)\n",
        "datasets.targets_loc = random.sample([(i,j) for i in range(const_HP.GSize) for j in range(const_HP.GSize)], const_HP.nof_targets)\n",
        "datasets.available_locs = [(i,j) for i in range(const_HP.GSize) for j in range(const_HP.GSize) if (i,j) not in datasets.targets_loc]\n",
        "datasets.false_targets_loc = random.sample(datasets.available_locs, const_HP.nof_false_targets)\n",
        "datasets.target_set = set()\n",
        "datasets.detect_img = np.zeros_like(datasets.grid, dtype=float)\n",
        "if const_HP.print:\n",
        "  print(datasets.grid)\n",
        "  print(datasets.agents_loc)\n",
        "  print(datasets.targets_loc)\n",
        "  print(datasets.false_targets_loc)\n",
        "  print(datasets.target_set)\n",
        "  print(datasets.detect_img)\n",
        "\n",
        "# ---- single figure, two axes ----\n",
        "fig, (Gax, Tax) = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "Gim = Gax.imshow(datasets.grid, cmap='viridis', vmin=0, vmax=1)\n",
        "Gax.set_title('Probabillity Grid'); fig.colorbar(Gim, ax=Gax)\n",
        "Tim = Tax.imshow(datasets.detect_img, cmap='viridis', vmin=0, vmax=const_HP.nof_iterations) # Changed vmax to nof_iterations\n",
        "Tax.set_title('Agents & Targets Locations'); fig.colorbar(Tim, ax=Tax)\n",
        "\n",
        "# draw static markers once\n",
        "ax = [c[1] for c in datasets.agents_loc]; ay = [c[0] for c in datasets.agents_loc]\n",
        "agents_scatter_T = Tax.scatter(ax, ay, marker='o', s=80, color='black', label='Agent')\n",
        "tx = [c[1] for c in datasets.targets_loc]; ty = [c[0] for c in datasets.targets_loc]\n",
        "Tax.scatter(tx, ty, marker='X', s=80, color='white', label='Targets')\n",
        "fx = [c[1] for c in datasets.false_targets_loc]; fy = [c[0] for c in datasets.false_targets_loc]\n",
        "Tax.scatter(fx, fy, marker='X', s=80, color='red', label='False Targets')\n",
        "Tax.legend(loc='upper right')\n",
        "\n",
        "# ----- main loop -----\n",
        "def update(frame):\n",
        "  if const_HP.print:\n",
        "    print_state(datasets, frame)\n",
        "\n",
        "  # # Check stopping condition at the beginning of the frame\n",
        "  # datasets.detected_target_locations = [(t[0], t[1]) for t in datasets.target_set]\n",
        "  # all_targets_detected = all(target in datasets.detected_target_locations for target in datasets.targets_loc)\n",
        "\n",
        "  # set stop when all targets found:\n",
        "  detected = {(i, j) for i, j, _ in datasets.target_set}\n",
        "  if detected.issuperset(datasets.targets_loc):\n",
        "      print(f\"All targets found at frame {frame}\")\n",
        "      stop_flag[\"stop\"] = True\n",
        "\n",
        "  # 1 step for every cell for all agents\n",
        "  for i in range(const_HP.GSize):\n",
        "    for j in range(const_HP.GSize):\n",
        "      inner_cell_loop(const_HP, var_HP, datasets, i, j, frame)\n",
        "\n",
        "  # Move the agents\n",
        "  move_all_agents(const_HP, var_HP, datasets)\n",
        "\n",
        "  # Update images and texts for the current frame\n",
        "  artists = set_images(const_HP, var_HP, datasets, Gim, Tim)\n",
        "\n",
        "  return artists\n",
        "\n",
        "stop_flag = {\"stop\": False}  # mutable flag shared with update()\n",
        "def frame_gen(max_frames):\n",
        "    f = 0\n",
        "    while f < max_frames and not stop_flag[\"stop\"]:\n",
        "        yield f\n",
        "        f += 1\n",
        "\n",
        "# ----- run -----\n",
        "# Build animation with generator (not a fixed range)\n",
        "anim = animation.FuncAnimation(\n",
        "    fig, update, frames=lambda: frame_gen(const_HP.nof_iterations),\n",
        "    interval=200, blit=False\n",
        ")\n",
        "HTML(anim.to_jshtml())"
      ],
      "metadata": {
        "id": "rF9WZuSO82TA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple Runs, no simulation\n",
        ">\n",
        "this version gets the constant hyper-parameters(HP):\n",
        "1. nof_runs (number of runs)\n",
        "2. max_frames\n",
        "3. gridsize\n",
        "4. nof_agents\n",
        "5. nof_targets\n",
        "6. nof_false_targets\n",
        "\n",
        "and the varying-HP:\n",
        "1. alpha\n",
        "2. lambda\n",
        "3. threshold\n",
        ">\n",
        "\n",
        "It then iterates over the varying-HP and tries to find the {max-alpha, min-lambda, max-threshold} combination that would still find all targets withough finding false-targets."
      ],
      "metadata": {
        "id": "YL7voyqW86TH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# List to store results from each run\n",
        "datasets.results = []\n",
        "\n",
        "const_HP.nof_runs = 1\n",
        "const_HP.max_frames = 2\n",
        "const_HP.GSize = 80\n",
        "# Randomize hyperparameters (example ranges, adjust as needed)\n",
        "var_HP.alpha = 0.3#0.50 #0.53 #random.uniform(0.1, 0.95)\n",
        "var_HP.lamda = 20#14.52 #random.uniform(5, 20)\n",
        "var_HP.threshold = 0.9#0.78 #random.uniform(0.7, 0.95)\n",
        "all_targets_detected = False\n",
        "reached_undetection = 3\n",
        "\n",
        "for run in range(const_HP.nof_runs):\n",
        "    print(f\"Starting run {run + 1}/{const_HP.nof_runs} with lamda {var_HP.lamda}\")\n",
        "\n",
        "    # Reset variables for each run\n",
        "    datasets.grid = np.full((const_HP.GSize, const_HP.GSize), const_HP.nof_targets/(const_HP.GSize**2), dtype=float)\n",
        "    # Re-randomize agent, target, and false target locations for each run\n",
        "    datasets.agents_loc = random.sample([(i,j) for i in range(const_HP.GSize) for j in range(const_HP.GSize)], const_HP.nof_agents)\n",
        "    datasets.targets_loc = random.sample([(i,j) for i in range(const_HP.GSize) for j in range(const_HP.GSize)], const_HP.nof_targets)\n",
        "    datasets.available_locs = [(i,j) for i in range(const_HP.GSize) for j in range(const_HP.GSize) if (i,j) not in datasets.targets_loc]\n",
        "    datasets.false_targets_loc = random.sample(datasets.available_locs, const_HP.nof_false_targets)\n",
        "\n",
        "    datasets.detect_img = np.zeros_like(datasets.grid, dtype=float)\n",
        "    datasets.target_set = set()\n",
        "    frames_taken = 0\n",
        "    false_target_detected = False # Flag to indicate if a false target was detected\n",
        "\n",
        "    # --- Simulation loop for a single run ---\n",
        "    for frame in range(const_HP.max_frames):\n",
        "        # Step model once (copying logic from the previous update function)\n",
        "        for i in range(const_HP.GSize):\n",
        "            for j in range(const_HP.GSize):\n",
        "                datasets.cell_by_agent = []\n",
        "                for a in datasets.agents_loc:\n",
        "                    d = np.hypot(a[0]-i, a[1]-j)\n",
        "                    s = cell_send_pulse(const_HP, var_HP, datasets, i, j) # Use current_alpha\n",
        "                    r = agent_recieved_signal(const_HP, var_HP, datasets, d) if s else 0 # Use current_lamda\n",
        "                    datasets.cell_by_agent.append(cell_update_probabillity(const_HP, var_HP, datasets, frame, datasets.grid[i][j], d, r))\n",
        "                update_cell(const_HP, var_HP, datasets, i, j, frame)\n",
        "                update_target_set(const_HP, var_HP, datasets, i, j, frame, datasets.grid[i][j]) # Use current_threshold\n",
        "\n",
        "        frames_taken = frame + 1\n",
        "\n",
        "        # Move the agents\n",
        "        agents_COM = datasets.agents_loc.mean(axis=0)\n",
        "        entropy_COM = calc_entropy_COM(datasets.grid)\n",
        "        for a in range(datasets.agents_loc.size()):\n",
        "          move_agent(const_HP, var_HP, datasets, a, agents_COM, entropy_COM)\n",
        "\n",
        "        # Check stopping condition\n",
        "        datasets.detected_target_locations = [(t[0], t[1]) for t in datasets.target_set]\n",
        "        if all(target in datasets.detected_target_locations for target in datasets.targets_loc):\n",
        "            print(f\"All targets detected in run {run + 1} at frame {frames_taken}\")\n",
        "            break\n",
        "\n",
        "        # Check if any detected location is a false target\n",
        "        if any(datasets.detected_loc in datasets.false_targets_loc for datasets.detected_loc in datasets.detected_target_locations):\n",
        "            false_target_detected = True\n",
        "            print(f\"False Target detected in run {run + 1} at frame {frames_taken}\")\n",
        "            break\n",
        "\n",
        "    # --- Collect results for the run ---\n",
        "    last_detected_target_frame = -1\n",
        "    last_detected_target_loc = None\n",
        "    if datasets.target_set:\n",
        "        # Find the target that was discovered last\n",
        "        # Filter out false targets before finding the last detected true target\n",
        "        datasets.true_targets_detected = [t for t in datasets.target_set if (t[0], t[1]) in datasets.targets_loc]\n",
        "        if datasets.true_targets_detected:\n",
        "          last_detected_target_info = max(datasets.true_targets_detected, key=lambda item: item[2])\n",
        "          last_detected_target_loc = (last_detected_target_info[0], last_detected_target_info[1])\n",
        "          last_detected_target_frame = last_detected_target_info[2]\n",
        "\n",
        "\n",
        "    avg_agent_distance_to_last_target = -1\n",
        "    if last_detected_target_loc:\n",
        "        distances = [np.hypot(a[0] - last_detected_target_loc[0], a[1] - last_detected_target_loc[1]) for a in datasets.agents_loc]\n",
        "        avg_agent_distance_to_last_target = np.mean(distances)\n",
        "\n",
        "    all_targets_detected = all(target in datasets.detected_target_locations for target in datasets.targets_loc)\n",
        "    if not all_targets_detected : reached_undetection = 1\n",
        "    print(f\"reached_undetection: {reached_undetection}\")\n",
        "    print(f\"all_targets_detected: {all_targets_detected}\")\n",
        "\n",
        "    datasets.results.append({\n",
        "        'run': run + 1,\n",
        "        'nof_agents': const_HP.nof_agents,\n",
        "        'nof_targets': const_HP.nof_targets,\n",
        "        'alpha': var_HP.alpha,\n",
        "        'lamda': var_HP.lamda,\n",
        "        'threshold': var_HP.threshold,\n",
        "        'frames_to_detect_all': frames_taken if all_targets_detected else -1, # -1 if not all detected\n",
        "        'avg_agent_distance_to_last_target': avg_agent_distance_to_last_target,\n",
        "        'false_target_detected': false_target_detected # Add the false target detection flag\n",
        "    })\n",
        "\n",
        "    for i in range(reached_undetection) :\n",
        "      choose_hyper = 1#random.choice([0,1,2])\n",
        "      match choose_hyper:\n",
        "        case 0:   var_HP.alpha += 0.01 if all_targets_detected else -0.01\n",
        "        case 1:   var_HP.lamda += -0.1 if all_targets_detected else 0.1\n",
        "        case 2:   var_HP.threshold += 0.01 if all_targets_detected else -0.01\n",
        "        case _:   print('ERROR')\n",
        "\n",
        "# Convert results to a pandas DataFrame\n",
        "results_df = pd.DataFrame(datasets.results)\n",
        "\n",
        "# Display the results\n",
        "display(results_df)"
      ],
      "metadata": {
        "id": "HPRIPQt987VY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}